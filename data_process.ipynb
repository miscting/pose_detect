{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parse Bin to excel Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameHeader:\n",
    "    def __init__(self, binary):\n",
    "        #self.magic_word = binary[0:8]\n",
    "        self.version = int.from_bytes(binary[0:4], 'little')\n",
    "        self.packet_length = int.from_bytes(binary[4:8], 'little')\n",
    "        self.platform = int.from_bytes(binary[8:12], 'little')\n",
    "        self.frame_number = int.from_bytes(binary[12:16], 'little')\n",
    "        self.time_cpu_cycle = int.from_bytes(binary[16:20], 'little')\n",
    "        self.num_del = int.from_bytes(binary[20:24], 'little')\n",
    "        self.num_tlv = int.from_bytes(binary[24:28], 'little')\n",
    "        self.subframe_no = int.from_bytes(binary[28:32], 'little')\n",
    "        self.tlv = []\n",
    "        ptr = 32\n",
    "        for n in range(self.num_tlv):\n",
    "            temp = TLV(binary[ptr:])\n",
    "            self.tlv.append(temp)\n",
    "            ptr += 8 + temp.tlv_header.length\n",
    "        self.binary = binary\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"binary :\"+str(self.binary)+\"\\nmagic word :\"+str(b'\\x02\\x01\\x04\\x03\\x06\\x05\\x08\\x07')+\"\\nversion :\"+str(self.version)+\"\\nframe_number :\"+str(self.frame_number)+\"\\npacket_length :\"+str(self.packet_length)+\"\\nnumber of TLV:\"+str(self.num_tlv)\n",
    "\n",
    "class TLVHeader: \n",
    "    def __init__(self, binary):\n",
    "        self.type = int.from_bytes(binary[0:4], 'little')\n",
    "        self.length = int.from_bytes(binary[4:8], 'little')\n",
    "\n",
    "# if type = 301\n",
    "class TLVPointCoord:\n",
    "    def __init__(self, binary):\n",
    "        xyzUnit = struct.unpack('<f', binary[0:4])[0]\n",
    "        dopplerUnit = struct.unpack('<f', binary[4:8])[0]\n",
    "        snrUnit = struct.unpack('<f', binary[8:12])[0]\n",
    "        noiseUnit = struct.unpack('<f', binary[12:16])[0]\n",
    "        # decompress all values\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.z = []\n",
    "        self.doppler = []\n",
    "        self.snr = []\n",
    "        self.noise = []\n",
    "        # start pointer at 20, throw 4 bytes away\n",
    "        ptr = 20\n",
    "        while ptr < len(binary):\n",
    "            ptr += 10\n",
    "            self.x.append(int.from_bytes(binary[ptr:ptr+2], 'little') * xyzUnit)\n",
    "            self.y.append(int.from_bytes(binary[ptr+2:ptr+4], 'little') * xyzUnit)\n",
    "            self.z.append(int.from_bytes(binary[ptr+4:ptr+6], 'little') * xyzUnit)\n",
    "            self.doppler.append(int.from_bytes(binary[ptr+6:ptr+8], 'little') * dopplerUnit)\n",
    "            self.snr.append(int.from_bytes(binary[ptr+8:ptr+9], 'little') * snrUnit)\n",
    "            self.noise.append(int.from_bytes(binary[ptr+9:ptr+10], 'little') * noiseUnit)\n",
    "        #self.rest = binary[ptr:]\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Service 301 \\nx :\"+str(self.x)+\"\\ny :\"+str(self.y)+\"\\nz:\"+str(self.z)+\"\\ndoppler:\"+str(self.doppler)+\"\\nsnr:\"+str(self.snr)+\"\\nnoise:\"+str(self.noise)+\"\\nrest of it:\"#+str(self.rest)\n",
    "\n",
    "# if type = 302/303\n",
    "class TLVTargetList:\n",
    "    def __init__(self, binary):\n",
    "        self.tid = []\n",
    "        self.posX = []\n",
    "        self.posY = []\n",
    "        self.posZ = []\n",
    "        self.velX = []\n",
    "        self.velY = []\n",
    "        self.velZ = []\n",
    "        self.accX = []\n",
    "        self.accY = []\n",
    "        self.accZ = []\n",
    "        self.gain = []\n",
    "        self.confidence = []\n",
    "        \n",
    "        targetStruct = 'I27f'\n",
    "        targetSize = struct.calcsize(targetStruct)\n",
    "        try:\n",
    "            targetData = struct.unpack(targetStruct,binary[:targetSize])\n",
    "        except:\n",
    "            print('ERROR: Target TLV parsing failed')\n",
    "        # ignore extra values \n",
    "        while (len(binary)> targetSize):\n",
    "            self.tid.append(targetData[0])\n",
    "            self.posX.append(targetData[1])\n",
    "            self.posY.append(targetData[2])\n",
    "            self.posZ.append(targetData[3])\n",
    "            self.velX.append(targetData[4])\n",
    "            self.velY.append(targetData[5])\n",
    "            self.velZ.append(targetData[6])\n",
    "            self.accX.append(targetData[7])\n",
    "            self.accY.append(targetData[8])\n",
    "            self.accZ.append(targetData[9])\n",
    "            self.gain.append(targetData[26])\n",
    "            self.confidence.append(targetData[27])\n",
    "            #throw EC away\n",
    "            binary = binary[targetSize:]\n",
    "            #self.re_len = len(binary)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Service 302/3 \\ntid :\"+str(self.tid)+\"\\nposX\"+str(self.posX)+\"\\nposY\"+str(self.posY)+\"\\nposZ\"+str(self.posZ)+\"\\nvelX\"+str(self.velX)+\"\\nvelY\"+str(self.velY)+\"\\nvelZ\"+str(self.velZ)+\"\\naccX\"+str(self.accX)+\"\\naccY\"+str(self.accY)+\"\\naccZ\"+str(self.accZ)+\"\\ngain\"+str(self.gain)+\"\\nconfidence\"+str(self.confidence)#+\"\\nRemaining:\"+str(self.re_len)\n",
    "\n",
    "#empty type for error messages\n",
    "class UnimplTLVService:\n",
    "    def __init__(self, type):\n",
    "        error = \"TLV Service \"+ str(type) + \" has not been implemented yet\"\n",
    "\n",
    "class TLVTargetIndex: \n",
    "    def __init__(self, binary):\n",
    "        self.index = []\n",
    "        for b in binary:\n",
    "            self.index.append(int(b))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Service 306 \\nIndexes :\" + str(self.index)\n",
    "    \n",
    "class TLVEnhancedPresenceIndication:\n",
    "    def __init__(self, binary):\n",
    "        pointStruct = '1b'  # While there are technically 2 bits per zone, we need to use at least 1 byte to represent\n",
    "        pointStructSize = struct.calcsize(pointStruct)\n",
    "        numZones = (binary[0]) # First byte in the TLV is the number of zones, the rest of it is the occupancy data\n",
    "        self.zonePresence = [0]\n",
    "        binary = binary[1:]\n",
    "        zoneCount = 0\n",
    "        while(zoneCount < numZones):\n",
    "            try:\n",
    "                idx = math.floor((zoneCount)/4)\n",
    "                self.zonePresence.append(binary[idx] >> (((zoneCount) * 2) % 8) & 3)\n",
    "                zoneCount = zoneCount + 1\n",
    "            except:\n",
    "                print('Error: Enhanced Presence Detection TLV Parser Failed')\n",
    "                break\n",
    "        binary = binary[pointStructSize:]\n",
    "    \n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Zone array is :\" + str(self.zonePresence)\n",
    "\n",
    "class TLV:\n",
    "    def __init__(self, binary):\n",
    "        self.tlv_header = TLVHeader(binary[0:8])\n",
    "        if self.tlv_header.type == 301:\n",
    "            self.tlv_value = TLVPointCoord(binary[8:8+self.tlv_header.length])\n",
    "        elif self.tlv_header.type == 308:# or self.tlv_header.type == 302 or self.tlv_header.type == 303:\n",
    "        #elif self.tlv_header.type == 302 or self.tlv_header.type ==303:\n",
    "            self.tlv_value = TLVTargetList(binary[8:8+self.tlv_header.length])\n",
    "        elif self.tlv_header.type == 309:\n",
    "        #elif self.tlv_header.type == 306:\n",
    "            self.tlv_value = TLVTargetIndex(binary[8:8+self.tlv_header.length])\n",
    "        elif self.tlv_header.type == 315:\n",
    "            self.tlv_value = TLVEnhancedPresenceIndication(binary[8:8+self.tlv_header.length])\n",
    "        else:\n",
    "            self.tlv_value = UnimplTLVService(self.tlv_header.type)\n",
    "            #print(\"Service out of range \" ,self.tlv_header.type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse binaries in a folder to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bin_file(file_path):\n",
    "    # Parses a single binary file and yields parsed frames as DataFrames\n",
    "\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    frames = data.split(b'\\x02\\x01\\x04\\x03\\x06\\x05\\x08\\x07')\n",
    "    frames = frames[1:]\n",
    "\n",
    "\n",
    "    for frame in frames:\n",
    "        frame_header = FrameHeader(frame)\n",
    "        df_frame = pd.DataFrame([])\n",
    "        for tlv in frame_header.tlv:                    \n",
    "            df_tlv = pd.DataFrame.from_dict(tlv.tlv_value.__dict__, orient=\"index\")\n",
    "            df_frame = pd.concat([df_frame, df_tlv])\n",
    "        yield df_frame\n",
    "\n",
    "# Folder containing the binary files\n",
    "folder_path = \"01_raw_bin/01_sitting_1000frames\"\n",
    "\n",
    "writer = pd.ExcelWriter(\"02_parsed/01_sitting_1000frames.xlsx\", engine='openpyxl')\n",
    "\n",
    "# Iterate through the binary files in the folder\n",
    "sheet_count = 1  # Track sheet number starting from 1\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".bin\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        for frame_df in parse_bin_file(file_path):\n",
    "            # Sheet name for each frame within a file\n",
    "            frame_number = str(sheet_count)\n",
    "            sheet_name = f\"{filename} - Frame {frame_number}\"\n",
    "            frame_df.to_excel(writer, sheet_name=sheet_name)\n",
    "            sheet_count += 1\n",
    "            \n",
    "# Save and close the Excel file\n",
    "writer._save()\n",
    "writer.close()\n",
    "\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = \"02_parsed/01_sitting_1000frames.xlsx\"\n",
    "xl = pd.ExcelFile(excel_file)\n",
    "\n",
    "frames_data = []\n",
    "\n",
    "# Iterate over each sheet in the Excel file\n",
    "for sheet_name in xl.sheet_names:\n",
    "    df = xl.parse(sheet_name)\n",
    "    \n",
    "    # Extracting specific rows and excluding the first column and row\n",
    "    frame_data = df.iloc[0:3, 1:].values\n",
    "    \n",
    "    # Remove columns where all values (excluding the first row) are either zero or NaN\n",
    "    mask = ~np.all(np.isnan(frame_data) | (frame_data == 0), axis=0)\n",
    "    frame_data = frame_data[:, mask]\n",
    "    \n",
    "    frames_data.append(frame_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Display dataset head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data for Frame 1:\")\n",
    "frame_data = frames_data[0]  # Frame indexing starts from 0\n",
    "print(frame_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Data Collection\n",
    "### A1. Read Parsed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load and clean data from an Excel file\n",
    "def load_frame_data(excel_file):\n",
    "    xl = pd.ExcelFile(excel_file)\n",
    "    frame_data_list = []\n",
    "    for sheet_name in xl.sheet_names:\n",
    "        df = xl.parse(sheet_name)\n",
    "        frame_data = df.iloc[0:3, 1:].values\n",
    "        mask = ~np.all(np.isnan(frame_data) | (frame_data == 0), axis=0)\n",
    "        frame_data = frame_data[:, mask]\n",
    "        # Ensure that there are at least 3 rows (x, y, z)\n",
    "        if frame_data.shape[0] == 3:\n",
    "            frame_data_list.append(frame_data)\n",
    "    return frame_data_list\n",
    "\n",
    "\n",
    "# Load data for sitting, lying, and curling\n",
    "excel_file_sitting = f\"02_parsed/01_sitting_1000frames.xlsx\"\n",
    "excel_file_lying = f\"02_parsed/01_lying_1000frames.xlsx\"\n",
    "excel_file_curling = f\"02_parsed/01_curling_1000frames.xlsx\"\n",
    "\n",
    "frame_data_sitting = load_frame_data(excel_file_sitting)\n",
    "frame_data_lying = load_frame_data(excel_file_lying)\n",
    "frame_data_curling = load_frame_data(excel_file_curling)\n",
    "\n",
    "'''\n",
    "print(\"Sitting Data for Frame 1:\")\n",
    "frame_data = frame_data_sitting[0]\n",
    "print(frame_data)\n",
    "\n",
    "print(\"Lying Data for Frame 1:\")\n",
    "frame_data = frame_data_lying[0]\n",
    "print(frame_data)\n",
    "\n",
    "print(\"Curling Data for Frame 1:\")\n",
    "frame_data = frame_data_curling[0]\n",
    "print(frame_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2. Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to plot the data for a given frame range\n",
    "def plot_xz_plane(frame_data_sitting, frame_data_lying, frame_data_curling, start_frame=1, end_frame=1000):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 7))\n",
    "\n",
    "    # Plot sitting data\n",
    "    for i in range(start_frame - 1, min(end_frame, len(frame_data_sitting))):\n",
    "        frame_data = frame_data_sitting[i]\n",
    "        x = frame_data[0]\n",
    "        z = frame_data[2]\n",
    "        axes[0].scatter(x, z, s=1)\n",
    "\n",
    "    # Plot lying data\n",
    "    for i in range(start_frame - 1, min(end_frame, len(frame_data_lying))):\n",
    "        frame_data = frame_data_lying[i]\n",
    "        x = frame_data[0]\n",
    "        z = frame_data[2]\n",
    "        axes[1].scatter(x, z, s=1)\n",
    "\n",
    "    # Plot curling data\n",
    "    for i in range(start_frame - 1, min(end_frame, len(frame_data_curling))):\n",
    "        frame_data = frame_data_curling[i]\n",
    "        x = frame_data[0]\n",
    "        z = frame_data[2]\n",
    "        axes[2].scatter(x, z, s=1)\n",
    "\n",
    "    axes[0].set_title('Sitting')\n",
    "    axes[1].set_title('Lying')\n",
    "    axes[2].set_title('Curling')\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Z')\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the XZ plane for frames 1 to 1000\n",
    "plot_xz_plane(frame_data_sitting, frame_data_lying, frame_data_curling, start_frame=1, end_frame=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3. Data Labelling & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Selective Cropping x > 2 and z < 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter the data based on given conditions\n",
    "def filter_frame_data(frame_data_list):\n",
    "    filtered_data_list = []\n",
    "    for frame_data in frame_data_list:\n",
    "        x = frame_data[0]\n",
    "        z = frame_data[2]\n",
    "        mask = (x >= 0) & (x <= 2) & (z >= 6) & (z <= 9)\n",
    "        filtered_frame_data = frame_data[:, mask]\n",
    "        filtered_data_list.append(filtered_frame_data)\n",
    "    return filtered_data_list\n",
    "\n",
    "# Filter the data for sitting, lying, and curling\n",
    "filtered_data_sitting = filter_frame_data(frame_data_sitting)\n",
    "filtered_data_lying = filter_frame_data(frame_data_lying)\n",
    "filtered_data_curling = filter_frame_data(frame_data_curling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the filtered data for a given frame range\n",
    "def plot_filtered_xz_plane(filtered_data_sitting, filtered_data_lying, filtered_data_curling, start_frame=1, end_frame=1000):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 7))\n",
    "\n",
    "    # Plot filtered sitting data\n",
    "    for i in range(start_frame - 1, min(end_frame, len(filtered_data_sitting))):\n",
    "        frame_data = filtered_data_sitting[i]\n",
    "        x = frame_data[0]\n",
    "        z = frame_data[2]\n",
    "        axes[0].scatter(x, z, s=1)\n",
    "\n",
    "    # Plot filtered lying data\n",
    "    for i in range(start_frame - 1, min(end_frame, len(filtered_data_lying))):\n",
    "        frame_data = filtered_data_lying[i]\n",
    "        x = frame_data[0]\n",
    "        z = frame_data[2]\n",
    "        axes[1].scatter(x, z, s=1)\n",
    "\n",
    "    # Plot filtered curling data\n",
    "    for i in range(start_frame - 1, min(end_frame, len(filtered_data_curling))):\n",
    "        frame_data = filtered_data_curling[i]\n",
    "        x = frame_data[0]\n",
    "        z = frame_data[2]\n",
    "        axes[2].scatter(x, z, s=1)\n",
    "\n",
    "    axes[0].set_title('Sitting')\n",
    "    axes[1].set_title('Lying')\n",
    "    axes[2].set_title('Curling')\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Z')\n",
    "        ax.set_xlim(0, 2)\n",
    "        ax.set_ylim(6, 10)\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the filtered XZ plane for frames 1 to 1000\n",
    "plot_filtered_xz_plane(filtered_data_sitting, filtered_data_lying, filtered_data_curling, start_frame=1, end_frame=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DBSCAN clustering to remove outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Function to concatenate XZ data from all frames into a single array\n",
    "def concatenate_frame_data(filtered_data_list):\n",
    "    concatenated_data = []\n",
    "    for frame_data in filtered_data_list:\n",
    "        x = frame_data[0]\n",
    "        z = frame_data[2]\n",
    "        points = np.vstack((x, z)).T\n",
    "        concatenated_data.append(points)\n",
    "    return np.concatenate(concatenated_data, axis=0)\n",
    "\n",
    "# Concatenate data for sitting, lying, and curling\n",
    "concat_data_sitting = concatenate_frame_data(filtered_data_sitting)\n",
    "concat_data_lying = concatenate_frame_data(filtered_data_lying)\n",
    "concat_data_curling = concatenate_frame_data(filtered_data_curling)\n",
    "\n",
    "# Perform DBSCAN clustering to remove outliers\n",
    "def dbscan_clustering(data, eps=0.025, min_samples=5):\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(data)\n",
    "    labels = clustering.labels_\n",
    "    # Separate inliers and outliers\n",
    "    inliers = data[labels != -1]\n",
    "    outliers = data[labels == -1]\n",
    "    return inliers, outliers\n",
    "\n",
    "# Apply DBSCAN clustering on concatenated data\n",
    "inliers_sitting, outliers_sitting = dbscan_clustering(concat_data_sitting)\n",
    "inliers_lying, outliers_lying = dbscan_clustering(concat_data_lying)\n",
    "inliers_curling, outliers_curling = dbscan_clustering(concat_data_curling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- visualize clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the filtered data with clustering results for a given frame range\n",
    "def plot_clustered_xz_plane(inliers_sitting, inliers_lying, inliers_curling, start_frame=1, end_frame=1000):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 7))\n",
    "\n",
    "    # Plot clustered sitting data\n",
    "    axes[0].scatter(inliers_sitting[:, 0], inliers_sitting[:, 1], s=1)\n",
    "    axes[0].set_title('Sitting')\n",
    "\n",
    "    # Plot clustered lying data\n",
    "    axes[1].scatter(inliers_lying[:, 0], inliers_lying[:, 1], s=1)\n",
    "    axes[1].set_title('Lying')\n",
    "\n",
    "    # Plot clustered curling data\n",
    "    axes[2].scatter(inliers_curling[:, 0], inliers_curling[:, 1], s=1)\n",
    "    axes[2].set_title('Curling')\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Z')\n",
    "        ax.set_xlim(0, 2)\n",
    "        ax.set_ylim(6, 10)\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the clustered XZ plane data\n",
    "plot_clustered_xz_plane(inliers_sitting, inliers_lying, inliers_curling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reassign Inlier Points to Original Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassign_inliers_to_frames(inliers, original_data):\n",
    "    frame_data_list = [np.zeros((3, 0)) for _ in range(len(original_data))]\n",
    "    for inlier in inliers:\n",
    "        x, z = inlier\n",
    "        for i, frame_data in enumerate(original_data):\n",
    "            mask = (frame_data[0] == x) & (frame_data[2] == z)\n",
    "            if np.any(mask):\n",
    "                frame_data_list[i] = np.hstack((frame_data_list[i], frame_data[:, mask]))\n",
    "                break\n",
    "    return frame_data_list\n",
    "\n",
    "# Reassign inliers to original frames\n",
    "filtered_data_sitting_inliers = reassign_inliers_to_frames(inliers_sitting, filtered_data_sitting)\n",
    "filtered_data_lying_inliers = reassign_inliers_to_frames(inliers_lying, filtered_data_lying)\n",
    "filtered_data_curling_inliers = reassign_inliers_to_frames(inliers_curling, filtered_data_curling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply Sliding Window (window size of 5 and a shift of 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sliding_window(data_list, window_size=5, shift=1):\n",
    "    sliding_window_data = []\n",
    "    for i in range(0, len(data_list) - window_size + 1, shift):\n",
    "        window_frames = data_list[i:i + window_size]\n",
    "        combined_frame = np.hstack(window_frames)\n",
    "        sliding_window_data.append(combined_frame)\n",
    "    return sliding_window_data\n",
    "\n",
    "# Apply sliding window on inlier data\n",
    "sliding_window_data_sitting = apply_sliding_window(filtered_data_sitting_inliers)\n",
    "sliding_window_data_lying = apply_sliding_window(filtered_data_lying_inliers)\n",
    "sliding_window_data_curling = apply_sliding_window(filtered_data_curling_inliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- remove empty frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_frames_after_sliding_window(sliding_window_data_list, activity_name):\n",
    "    print(f\"Initial number of frames in {activity_name} after sliding window: {len(sliding_window_data_list)}\")\n",
    "    filtered_frames = [frame for frame in sliding_window_data_list if frame.shape[1] > 0]\n",
    "    print(f\"Number of frames in {activity_name} after removing empty frames: {len(filtered_frames)}\")\n",
    "    return filtered_frames\n",
    "\n",
    "# Remove empty frames after sliding window\n",
    "nonempty_data_sitting = remove_empty_frames_after_sliding_window(sliding_window_data_sitting, \"sitting\")\n",
    "nonempty_data_lying = remove_empty_frames_after_sliding_window(sliding_window_data_lying, \"lying\")\n",
    "nonempty_data_curling = remove_empty_frames_after_sliding_window(sliding_window_data_curling, \"curling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A4. Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_frames(filtered_frames):\n",
    "    normalized_frames = []\n",
    "\n",
    "    # Define the maximum sequence length\n",
    "    max_length = max(len(frame[0]) for frame in filtered_frames)\n",
    "\n",
    "    # Iterate over each frame in filtered_frames\n",
    "    for frame in filtered_frames:\n",
    "        # Extract X and Z values from the frame's data\n",
    "        x_values = frame[0]\n",
    "        z_values = frame[2]\n",
    "\n",
    "        # Pad or truncate the sequences to match the maximum length\n",
    "        padded_x_values = np.pad(x_values, (0, max_length - len(x_values)), mode='constant', constant_values=0)\n",
    "        padded_z_values = np.pad(z_values, (0, max_length - len(z_values)), mode='constant', constant_values=0)\n",
    "\n",
    "        # Normalize X and Z values within the specified range\n",
    "        normalized_x = (padded_x_values - 0) / (2 - 0)  # Normalize within 0 to 2 range\n",
    "        normalized_z = (padded_z_values - 6) / (10 - 6)  # Normalize within 6 to 10 range\n",
    "\n",
    "        # Create a mask to filter out Z values above 0.8 and below 0.4\n",
    "        mask = (normalized_z >= 0.4) & (normalized_z <= 0.8)\n",
    "\n",
    "        # Apply the mask to the normalized values\n",
    "        filtered_x = normalized_x[mask]\n",
    "        filtered_z = normalized_z[mask]\n",
    "\n",
    "        # Append filtered normalized X and Z values to the normalized frames\n",
    "        normalized_frames.append([filtered_x, filtered_z])\n",
    "\n",
    "    return normalized_frames\n",
    "\n",
    "# Normalize the data for sitting, lying, and curling\n",
    "normalized_data_sitting = normalize_frames(nonempty_data_sitting)\n",
    "normalized_data_lying = normalize_frames(nonempty_data_lying)\n",
    "normalized_data_curling = normalize_frames(nonempty_data_curling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose x random frames from each pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def select_random_frames(normalized_data, num_frames, seed=42):\n",
    "    random.seed(seed)\n",
    "    random.shuffle(normalized_data)\n",
    "    return normalized_data[:num_frames]\n",
    "\n",
    "# Select 300 random frames for each pose\n",
    "selected_data_sitting = select_random_frames(normalized_data_sitting, num_frames=300)\n",
    "selected_data_lying = select_random_frames(normalized_data_lying, num_frames=300)\n",
    "selected_data_curling = select_random_frames(normalized_data_curling, num_frames=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the selected data for a given frame range\n",
    "def plot_selected_xz_plane(selected_data_sitting, selected_data_lying, selected_data_curling):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 7))\n",
    "\n",
    "    # Plot selected sitting data\n",
    "    for frame_data in selected_data_sitting:\n",
    "        x = frame_data[0]\n",
    "        z = frame_data[1]\n",
    "        axes[0].scatter(x, z, s=1)\n",
    "\n",
    "    # Plot selected lying data\n",
    "    for frame_data in selected_data_lying:\n",
    "        x = frame_data[0]\n",
    "        z = frame_data[1]\n",
    "        axes[1].scatter(x, z, s=1)\n",
    "\n",
    "    # Plot selected curling data\n",
    "    for frame_data in selected_data_curling:\n",
    "        x = frame_data[0]\n",
    "        z = frame_data[1]\n",
    "        axes[2].scatter(x, z, s=1)\n",
    "\n",
    "    axes[0].set_title('Sitting')\n",
    "    axes[1].set_title('Lying')\n",
    "    axes[2].set_title('Curling')\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Z')\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the selected XZ plane data\n",
    "plot_selected_xz_plane(selected_data_sitting, selected_data_lying, selected_data_curling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A6. Convert to image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to create occupancy grid image for each frame\n",
    "def create_occupancy_grid_for_frames(slide_array, num_frames, output_folder):\n",
    "    # Ensure the output subfolder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Iterate over each frame in the sequence\n",
    "    for frame_index in range(num_frames):\n",
    "        frame_data = slide_array[frame_index]\n",
    "\n",
    "        # Define grid size\n",
    "        grid_size = 100\n",
    "\n",
    "        # Create occupancy grid\n",
    "        occupancy_grid = np.zeros((grid_size, grid_size))\n",
    "\n",
    "        # Scale normalized XZ coordinates to fit within the grid size\n",
    "        x_values = np.clip(frame_data[0] * (grid_size - 1), 0, grid_size - 1)\n",
    "        z_values = np.clip(frame_data[1] * (grid_size - 1), 0, grid_size - 1)\n",
    "\n",
    "        # Update occupancy grid\n",
    "        for x, z in zip(x_values, z_values):\n",
    "            grid_x = int(x)\n",
    "            grid_y = int(z)\n",
    "            occupancy_grid[grid_y, grid_x] = 1\n",
    "\n",
    "        # Create figure and plot occupancy grid\n",
    "        fig, ax = plt.subplots(figsize=(grid_size * 1.3 / 100, grid_size * 1.3 / 100))\n",
    "        ax.imshow(occupancy_grid, cmap='gray', origin='lower', extent=[0, grid_size, 0, grid_size])\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Save the figure without margins\n",
    "        plt.savefig(os.path.join(output_folder, f\"frame_{frame_index + 1}.png\"), bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)  # Close the figure explicitly\n",
    "\n",
    "# Specify the output folder where the images will be saved\n",
    "output_folder = f\"03_occupancy_grid/01_set\"\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define number of frames for each dataset\n",
    "num_frames_sitting = len(selected_data_sitting)\n",
    "num_frames_lying = len(selected_data_lying)\n",
    "num_frames_curling = len(selected_data_curling)\n",
    "\n",
    "# Call the function to generate and save images for each dataset\n",
    "create_occupancy_grid_for_frames(selected_data_sitting, num_frames_sitting, os.path.join(output_folder, \"sitting\"))\n",
    "create_occupancy_grid_for_frames(selected_data_lying, num_frames_lying, os.path.join(output_folder, \"lying\"))\n",
    "create_occupancy_grid_for_frames(selected_data_curling, num_frames_curling, os.path.join(output_folder, \"curling\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
